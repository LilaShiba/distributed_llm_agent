# Copy this file to .env and customize for your setup

# === Network ===
# Where workers are located (for local docker-compose)
WORKER_URLS=http://worker1:5000,http://worker2:5000

# For Docker Swarm, use the service name instead
# WORKER_SERVICE=llm_worker
# WORKER_PORT=5000

# Router listen address
HOST=0.0.0.0
PORT=5000

# === Timeouts (seconds) ===
# How long to wait for worker health check
HEALTH_TIMEOUT=2

# How long to wait for inference response
REQUEST_TIMEOUT=30

# How many times to retry if a worker fails
MAX_RETRIES=2

# === Model ===
# HuggingFace model to use
# Light models: distilgpt2, distilbert-base-uncased
# Medium: gpt2, gpt-neo-125M
# Large: gpt-neo-2.7B (requires >4GB RAM)
MODEL_NAME=distilgpt2

# Max tokens to generate
MAX_LENGTH=100

# Temperature controls randomness (0=deterministic, 1=more random)
TEMPERATURE=0.7

# Use sampling (True) or greedy (False) for generation
DO_SAMPLE=True

# === System ===
# Enable debug mode (True/False)
DEBUG=False

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Where to save log files
LOGS_DIR=logs
